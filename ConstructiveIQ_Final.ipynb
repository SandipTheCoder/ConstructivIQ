{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAivJNQ0UVOh9LFzL2GlfH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SandipTheCoder/ConstructivIQ/blob/main/ConstructiveIQ_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZgcfB2fP6Zm",
        "outputId": "91be0b71-a1fc-4af8-8d0c-8531d705af05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/ConstructivIQ/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4pn4JLmP7RC",
        "outputId": "7d972e1c-ddea-4397-ad64-5ff2affd8b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/ConstructivIQ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the datasets\n",
        "materials = pd.read_csv(\"materials.csv\")\n",
        "test_pairs = pd.read_csv(\"test_pairs.csv\")\n",
        "\n",
        "# Display dataset info\n",
        "print(\"Materials Dataset Head:\")\n",
        "print(materials.head())\n",
        "\n",
        "print(\"\\nTest Pairs Dataset Head:\")\n",
        "print(test_pairs.head())\n",
        "\n",
        "# Step 1: Preprocess the material descriptions using TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(materials['Material_Description'])\n",
        "\n",
        "# Create a mapping from material ID to its TF-IDF vector\n",
        "material_id_to_vector = dict(zip(materials['ID'], tfidf_matrix))\n",
        "\n",
        "# Step 2: Compute similarity for test pairs\n",
        "def compute_similarity(id1, id2):\n",
        "    # Retrieve the TF-IDF vectors for the material IDs\n",
        "    vector1 = material_id_to_vector.get(id1)\n",
        "    vector2 = material_id_to_vector.get(id2)\n",
        "    if vector1 is not None and vector2 is not None:\n",
        "        # Compute cosine similarity between the two vectors\n",
        "        similarity = cosine_similarity(vector1, vector2)[0][0]\n",
        "        return similarity\n",
        "    return 0.0  # Default to 0 if vector is not found\n",
        "\n",
        "# Apply similarity computation to test pairs\n",
        "test_pairs['Similarity_Score'] = test_pairs.apply(\n",
        "    lambda row: compute_similarity(row['ID_1'], row['ID_2']), axis=1\n",
        ")\n",
        "\n",
        "# Step 3: Save the results in the required submission format\n",
        "test_pairs[['ID_1', 'ID_2', 'Similarity_Score']].to_csv(\n",
        "    \"submission.csv\", index=False\n",
        ")\n",
        "\n",
        "print(\"Submission saved to submission.csv!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94jC5GDBQ9QA",
        "outputId": "f746d749-9a0d-438f-e789-815ccf6f8d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Materials Dataset Head:\n",
            "   ID                               Material_Description\n",
            "0   1  INSULATION GASKET KIT - 2\" - 300# - DOUBLE COM...\n",
            "1   2  ASSEMBLY COMPRESSOR - 10\" - 150# - HOT DIP GAL...\n",
            "2   3  SPUR GEAR PINION SHAFT - 10\" - 150# - SCH.XS A...\n",
            "3   4  SUCTION HEADER - 6\" - 600# - HOT DIP GALVANIZE...\n",
            "4   5  MOVABLE STOOL - 6\" - 150# - DUAL CERTIFIED, DR...\n",
            "\n",
            "Test Pairs Dataset Head:\n",
            "   ID_1  ID_2\n",
            "0   375   932\n",
            "1   588    22\n",
            "2   876   724\n",
            "3   270   154\n",
            "4   512   544\n",
            "Submission saved to submission.csv!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the submission file\n",
        "submission_file = \"submission.csv\"\n",
        "submission = pd.read_csv(submission_file)\n",
        "\n",
        "# Step 1: Check the first few rows\n",
        "print(\"Submission File Head:\")\n",
        "print(submission.head())\n",
        "\n",
        "# Step 2: Check columns\n",
        "required_columns = ['ID_1', 'ID_2', 'Similarity_Score']\n",
        "if all(col in submission.columns for col in required_columns):\n",
        "    print(\"\\nAll required columns are present.\")\n",
        "else:\n",
        "    print(\"\\nError: Missing required columns!\")\n",
        "\n",
        "# Step 3: Validate similarity scores are within the range [0, 1]\n",
        "invalid_scores = submission[(submission['Similarity_Score'] < 0) | (submission['Similarity_Score'] > 1)]\n",
        "if invalid_scores.empty:\n",
        "    print(\"\\nAll similarity scores are valid (between 0 and 1).\")\n",
        "else:\n",
        "    print(\"\\nInvalid similarity scores found:\")\n",
        "    print(invalid_scores)\n",
        "\n",
        "# Step 4: Check number of rows matches the test_pairs dataset\n",
        "test_pairs = pd.read_csv(\"test_pairs.csv\")\n",
        "if len(submission) == len(test_pairs):\n",
        "    print(\"\\nThe number of rows matches the test_pairs dataset.\")\n",
        "else:\n",
        "    print(f\"\\nMismatch in row count: Submission has {len(submission)} rows, \"\n",
        "          f\"but test_pairs has {len(test_pairs)} rows.\")\n",
        "\n",
        "print(\"\\nValidation completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUpo_sbcQ_39",
        "outputId": "c30b1311-4bd2-4387-f9e3-ad2c8f348224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission File Head:\n",
            "   ID_1  ID_2  Similarity_Score\n",
            "0   375   932          0.071704\n",
            "1   588    22          0.110973\n",
            "2   876   724          0.059701\n",
            "3   270   154          0.162412\n",
            "4   512   544          0.026452\n",
            "\n",
            "All required columns are present.\n",
            "\n",
            "All similarity scores are valid (between 0 and 1).\n",
            "\n",
            "The number of rows matches the test_pairs dataset.\n",
            "\n",
            "Validation completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y7sYG1j6RI3b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}