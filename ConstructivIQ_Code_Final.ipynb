{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGpO16wcuQsgRetSdPt1kX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SandipTheCoder/ConstructivIQ/blob/main/ConstructivIQ_Code_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FatGOeWib5HH",
        "outputId": "fcc96e16-bb2e-4e1b-955c-8e569b45ba75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/ConstructivIQ_Code/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rapKJtEnb8na",
        "outputId": "e0fbf52d-1e99-4e98-b6cb-f8468855450f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/ConstructivIQ_Code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Code"
      ],
      "metadata": {
        "id": "LXUBza1Gds4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the datasets\n",
        "materials = pd.read_csv(\"materials.csv\")\n",
        "test_pairs = pd.read_csv(\"test_pairs.csv\")\n",
        "\n",
        "# Display dataset info\n",
        "print(\"Materials Dataset Head:\")\n",
        "print(materials.head())\n",
        "\n",
        "print(\"\\nTest Pairs Dataset Head:\")\n",
        "print(test_pairs.head())\n",
        "\n",
        "# Step 1: Preprocess the material descriptions using TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(materials['Material_Description'])\n",
        "\n",
        "# Create a mapping from material ID to its TF-IDF vector\n",
        "material_id_to_vector = dict(zip(materials['ID'], tfidf_matrix))\n",
        "\n",
        "# Step 2: Compute similarity scores for each test pair\n",
        "def compute_similarity(id1, id2):\n",
        "    # Retrieve the TF-IDF vectors for the material IDs\n",
        "    vector1 = material_id_to_vector.get(id1)\n",
        "    vector2 = material_id_to_vector.get(id2)\n",
        "    if vector1 is not None and vector2 is not None:\n",
        "        # Compute cosine similarity between the two vectors\n",
        "        similarity = cosine_similarity(vector1, vector2)[0][0]\n",
        "        return similarity\n",
        "    return 0.0  # Default to 0 if vector is not found\n",
        "\n",
        "# Add similarity scores for each test pair\n",
        "test_pairs['Similarity_Score'] = test_pairs.apply(\n",
        "    lambda row: compute_similarity(row['ID_1'], row['ID_2']), axis=1\n",
        ")\n",
        "\n",
        "# Step 3: Generate predictions for MAP@K\n",
        "# Create a dictionary where each ID_1 maps to a list of predicted IDs (ranked by similarity)\n",
        "predicted_rankings = (\n",
        "    test_pairs.sort_values(by=['ID_1', 'Similarity_Score'], ascending=[True, False])\n",
        "    .groupby('ID_1')['ID_2']\n",
        "    .apply(list)\n",
        "    .to_dict()\n",
        ")\n",
        "\n",
        "# Ground truth: Assume all pairs in the test set are relevant for this example\n",
        "ground_truth = test_pairs.groupby('ID_1')['ID_2'].apply(list).to_dict()\n",
        "\n",
        "# Step 4: Define MAP@K function\n",
        "def apk(actual, predicted, k):\n",
        "    \"\"\"\n",
        "    Computes the Average Precision at K (AP@K).\n",
        "    \"\"\"\n",
        "    if not actual or not predicted:\n",
        "        return 0.0\n",
        "\n",
        "    predicted = predicted[:k]\n",
        "    score = 0.0\n",
        "    num_hits = 0\n",
        "\n",
        "    for i, p in enumerate(predicted):\n",
        "        if p in actual and p not in predicted[:i]:  # Avoid duplicates\n",
        "            num_hits += 1\n",
        "            score += num_hits / (i + 1.0)\n",
        "\n",
        "    return score / min(len(actual), k)\n",
        "\n",
        "def mapk(actual_dict, predicted_dict, k):\n",
        "    \"\"\"\n",
        "    Computes Mean Average Precision at K (MAP@K).\n",
        "    \"\"\"\n",
        "    apk_scores = [\n",
        "        apk(actual_dict.get(key, []), predicted_dict.get(key, []), k)\n",
        "        for key in predicted_dict.keys()\n",
        "    ]\n",
        "    return sum(apk_scores) / len(apk_scores)\n",
        "\n",
        "# Step 5: Compute MAP@K\n",
        "k = 10  # Define the value of K\n",
        "mapk_score = mapk(ground_truth, predicted_rankings, k)\n",
        "\n",
        "print(f\"MAP@{k}: {mapk_score:.4f}\")\n",
        "\n",
        "\n",
        "# Step 6: Save the results in the required submission format\n",
        "test_pairs[['ID_1', 'ID_2', 'Similarity_Score']].to_csv(\n",
        "    \"submission.csv\", index=False\n",
        ")\n",
        "\n",
        "print(\"Submission saved to submission.csv!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itYTYpmNcJ00",
        "outputId": "1802c3db-dc7c-4f70-d83f-93f4be2af727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Materials Dataset Head:\n",
            "   ID                               Material_Description\n",
            "0   1  INSULATION GASKET KIT - 2\" - 300# - DOUBLE COM...\n",
            "1   2  ASSEMBLY COMPRESSOR - 10\" - 150# - HOT DIP GAL...\n",
            "2   3  SPUR GEAR PINION SHAFT - 10\" - 150# - SCH.XS A...\n",
            "3   4  SUCTION HEADER - 6\" - 600# - HOT DIP GALVANIZE...\n",
            "4   5  MOVABLE STOOL - 6\" - 150# - DUAL CERTIFIED, DR...\n",
            "\n",
            "Test Pairs Dataset Head:\n",
            "   ID_1  ID_2\n",
            "0   375   932\n",
            "1   588    22\n",
            "2   876   724\n",
            "3   270   154\n",
            "4   512   544\n",
            "MAP@10: 1.0000\n",
            "Submission saved to submission.csv!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation Code"
      ],
      "metadata": {
        "id": "MT0f-MupdxPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the submission file\n",
        "submission_file = \"submission.csv\"\n",
        "submission = pd.read_csv(submission_file)\n",
        "\n",
        "# Step 1: Check the first few rows\n",
        "print(\"Submission File Head:\")\n",
        "print(submission.head())\n",
        "\n",
        "# Step 2: Check columns\n",
        "required_columns = ['ID_1', 'ID_2', 'Similarity_Score']\n",
        "if all(col in submission.columns for col in required_columns):\n",
        "    print(\"\\nAll required columns are present.\")\n",
        "else:\n",
        "    print(\"\\nError: Missing required columns!\")\n",
        "\n",
        "# Step 3: Validate similarity scores are within the range [0, 1]\n",
        "invalid_scores = submission[(submission['Similarity_Score'] < 0) | (submission['Similarity_Score'] > 1)]\n",
        "if invalid_scores.empty:\n",
        "    print(\"\\nAll similarity scores are valid (between 0 and 1).\")\n",
        "else:\n",
        "    print(\"\\nInvalid similarity scores found:\")\n",
        "    print(invalid_scores)\n",
        "\n",
        "# Step 4: Check number of rows matches the test_pairs dataset\n",
        "test_pairs = pd.read_csv(\"test_pairs.csv\")\n",
        "if len(submission) == len(test_pairs):\n",
        "    print(\"\\nThe number of rows matches the test_pairs dataset.\")\n",
        "else:\n",
        "    print(f\"\\nMismatch in row count: Submission has {len(submission)} rows, \"\n",
        "          f\"but test_pairs has {len(test_pairs)} rows.\")\n",
        "\n",
        "print(\"\\nValidation completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZsT7r0ncRhz",
        "outputId": "f0c6bb29-c8b8-4259-ecc1-b8f738dc6904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission File Head:\n",
            "   ID_1  ID_2  Similarity_Score\n",
            "0   375   932          0.071704\n",
            "1   588    22          0.110973\n",
            "2   876   724          0.059701\n",
            "3   270   154          0.162412\n",
            "4   512   544          0.026452\n",
            "\n",
            "All required columns are present.\n",
            "\n",
            "All similarity scores are valid (between 0 and 1).\n",
            "\n",
            "The number of rows matches the test_pairs dataset.\n",
            "\n",
            "Validation completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qZ0dGUHHdfci"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}